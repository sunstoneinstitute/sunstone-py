{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Sunstone Python Library","text":"<p>A Python library for managing datasets with lineage tracking in data science projects.</p> <p> </p>"},{"location":"#features","title":"Features","text":"<ul> <li>Automatic Lineage Tracking: Track data provenance through all operations automatically</li> <li>Dataset Management: Integration with <code>datasets.yaml</code> for organized dataset registration</li> <li>Pandas-Compatible API: Familiar pandas-like interface via <code>from sunstone import pandas as pd</code></li> <li>Strict/Relaxed Modes: Control whether operations can modify <code>datasets.yaml</code></li> <li>Validation Tools: Check notebooks and scripts for correct import usage</li> <li>Full Type Hints: Complete type hint support for better IDE integration</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># Using uv (recommended)\nuv add sunstone-py\n\n# Using pip\npip install sunstone-py\n</code></pre> <p>To use the latest commit from github:</p> <pre><code>dependencies = [\n    \"sunstone-py @ git+https://github.com/sunstoneinstitute/sunstone-py.git\",\n]\n</code></pre> <p>If you are making changes to sunstone-py checked out at <code>~/git/sunstone-py</code> and testing them directly from your project:</p> <pre><code>dependencies = [\n    \"sunstone-py @ file://${HOME}/git/sunstone-py\"\n]\n</code></pre>"},{"location":"#for-development","title":"For Development","text":"<pre><code>git clone https://github.com/sunstoneinstitute/sunstone-py.git\ncd sunstone-py\nuv venv\nuv sync\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#1-set-up-your-project-with-datasetsyaml","title":"1. Set Up Your Project with datasets.yaml","text":"<p>Create a <code>datasets.yaml</code> file in your project directory:</p> <pre><code>inputs:\n  - name: School Data\n    slug: school-data\n    location: data/schools.csv\n    source:\n      name: Ministry of Education\n      location:\n        data: https://example.com/schools.csv\n      attributedTo: Ministry of Education\n      acquiredAt: 2025-01-15\n      acquisitionMethod: manual-download\n      license: CC-BY-4.0\n    fields:\n      - name: school_id\n        type: string\n      - name: enrollment\n        type: integer\n\noutputs: []\n</code></pre>"},{"location":"#2-use-pandas-like-api-with-lineage-tracking","title":"2. Use Pandas-Like API with Lineage Tracking","text":"<pre><code>from sunstone import pandas as pd\nfrom pathlib import Path\n\n# Set project path (where datasets.yaml lives)\nPROJECT_PATH = Path.cwd()\n\n# Read data - lineage automatically tracked\ndf = pd.read_csv('data/schools.csv', project_path=PROJECT_PATH)\n\n# Transform using familiar pandas operations\nresult = df[df['enrollment'] &gt; 100].groupby('district').sum()\n\n# Save with automatic lineage tracking and dataset registration\nresult.to_csv(\n    'outputs/summary.csv',\n    slug='school-summary',\n    name='School Enrollment Summary',\n    index=False\n)\n</code></pre>"},{"location":"#3-check-lineage-metadata","title":"3. Check Lineage Metadata","text":"<pre><code># View lineage information\nprint(result.lineage.sources)      # Source datasets\nprint(result.lineage.operations)   # Operations performed\nprint(result.lineage.get_licenses())  # All source licenses\n</code></pre>"},{"location":"#core-concepts","title":"Core Concepts","text":""},{"location":"#pandas-like-api","title":"Pandas-Like API","text":"<p>sunstone-py provides a drop-in replacement for pandas that adds lineage tracking:</p> <pre><code>from sunstone import pandas as pd\n\n# Works like pandas, but tracks lineage\ndf = pd.read_csv('input.csv', project_path='/path/to/project')\ndf2 = pd.read_csv('input2.csv', project_path='/path/to/project')\n\n# All pandas operations work\nfiltered = df[df['value'] &gt; 100]\ngrouped = df.groupby('category').sum()\n\n# Merge/join operations combine lineage from both sources\nmerged = pd.merge(df, df2, on='key')\nconcatenated = pd.concat([df, df2])\n</code></pre>"},{"location":"#strict-vs-relaxed-mode","title":"Strict vs Relaxed Mode","text":"<p>Relaxed Mode (default):</p> <ul> <li>Writing to new outputs auto-registers them in <code>datasets.yaml</code></li> <li>More flexible for exploratory work</li> </ul> <p>Strict Mode:</p> <ul> <li>All reads and writes must be pre-registered in <code>datasets.yaml</code></li> <li>Ensures complete documentation of data operations</li> <li>Enable via <code>strict=True</code> parameter or <code>SUNSTONE_DATAFRAME_STRICT=1</code> environment variable</li> </ul> <pre><code># Enable strict mode\ndf = pd.read_csv('data.csv', project_path=PROJECT_PATH, strict=True)\n\n# Or globally\nimport os\nos.environ['SUNSTONE_DATAFRAME_STRICT'] = '1'\n</code></pre>"},{"location":"#validation-tools","title":"Validation Tools","text":"<p>Check notebooks for correct import usage:</p> <pre><code>import sunstone\n\n# Check a single notebook\nresult = sunstone.check_notebook_imports('analysis.ipynb')\nprint(result.summary())\n\n# Check all notebooks in project\nresults = sunstone.validate_project_notebooks('/path/to/project')\nfor path, result in results.items():\n    if not result.is_valid:\n        print(f\"\\n{path}:\")\n        print(result.summary())\n</code></pre>"},{"location":"#advanced-usage","title":"Advanced Usage","text":""},{"location":"#direct-dataframe-api","title":"Direct DataFrame API","text":"<p>For more control, use the DataFrame class directly:</p> <pre><code>from sunstone import DataFrame\n\n# Read with explicit parameters\ndf = DataFrame.read_csv(\n    'data.csv',\n    project_path='/path/to/project',\n    strict=True\n)\n\n# Apply custom operations with lineage tracking\nresult = df.apply_operation(\n    lambda d: d[d['value'] &gt; 100],\n    description=\"Filter high-value rows\"\n)\n\n# Access underlying pandas DataFrame\npandas_df = result.data\n</code></pre>"},{"location":"#managing-datasetsyaml-programmatically","title":"Managing datasets.yaml Programmatically","text":"<pre><code>from sunstone import DatasetsManager, FieldSchema\n\nmanager = DatasetsManager('/path/to/project')\n\n# Find datasets\ndataset = manager.find_dataset_by_slug('school-data')\ndataset = manager.find_dataset_by_location('data/schools.csv')\n\n# Add new output dataset\nmanager.add_output_dataset(\n    name='Analysis Results',\n    slug='analysis-results',\n    location='outputs/results.csv',\n    fields=[\n        FieldSchema(name='category', type='string'),\n        FieldSchema(name='count', type='integer'),\n        FieldSchema(name='avg_value', type='number')\n    ],\n    publish=True\n)\n</code></pre>"},{"location":"#api-reference","title":"API Reference","text":""},{"location":"#pandas-module","title":"pandas Module","text":"<p>Drop-in replacement for pandas with lineage tracking:</p> <ul> <li><code>read_csv(filepath, project_path, strict=False, **kwargs)</code>: Read CSV with lineage</li> <li><code>read_json(filepath, project_path, strict=False, **kwargs)</code>: Read JSON with lineage</li> <li><code>merge(left, right, **kwargs)</code>: Merge DataFrames with combined lineage</li> <li><code>concat(dfs, **kwargs)</code>: Concatenate DataFrames with combined lineage</li> </ul>"},{"location":"#dataframe-class","title":"DataFrame Class","text":"<p>Main class for working with data:</p> <ul> <li><code>read_csv(filepath, project_path, strict=False, **kwargs)</code>: Read CSV with lineage tracking</li> <li><code>to_csv(path, slug, name, publish=False, **kwargs)</code>: Write CSV and register</li> <li><code>merge(right, **kwargs)</code>: Merge with another DataFrame</li> <li><code>join(other, **kwargs)</code>: Join with another DataFrame</li> <li><code>concat(others, **kwargs)</code>: Concatenate DataFrames</li> <li><code>apply_operation(operation, description)</code>: Apply transformation with lineage</li> <li><code>.data</code>: Access underlying pandas DataFrame</li> <li><code>.lineage</code>: Access lineage metadata</li> </ul>"},{"location":"#datasetsmanager-class","title":"DatasetsManager Class","text":"<p>Manage <code>datasets.yaml</code> files:</p> <ul> <li><code>find_dataset_by_location(location, dataset_type='input')</code>: Find by file path</li> <li><code>find_dataset_by_slug(slug, dataset_type='input')</code>: Find by slug</li> <li><code>get_all_inputs()</code>: Get all input datasets</li> <li><code>get_all_outputs()</code>: Get all output datasets</li> <li><code>add_output_dataset(...)</code>: Register new output</li> <li><code>update_output_dataset(...)</code>: Update existing output</li> </ul>"},{"location":"#validation-functions","title":"Validation Functions","text":"<ul> <li><code>check_notebook_imports(notebook_path)</code>: Validate a single notebook</li> <li><code>validate_project_notebooks(project_path)</code>: Validate all notebooks in project</li> </ul>"},{"location":"#exceptions","title":"Exceptions","text":"<ul> <li><code>SunstoneError</code>: Base exception</li> <li><code>DatasetNotFoundError</code>: Dataset not found in datasets.yaml</li> <li><code>StrictModeError</code>: Operation blocked in strict mode</li> <li><code>DatasetValidationError</code>: Validation failed</li> <li><code>LineageError</code>: Lineage tracking error</li> </ul>"},{"location":"#environment-variables","title":"Environment Variables","text":"<ul> <li><code>SUNSTONE_DATAFRAME_STRICT</code>: Set to <code>\"1\"</code> or <code>\"true\"</code> to enable strict mode globally</li> </ul>"},{"location":"#development","title":"Development","text":""},{"location":"#running-tests","title":"Running Tests","text":"<pre><code>uv run pytest\n</code></pre>"},{"location":"#type-checking","title":"Type Checking","text":"<pre><code>uv run mypy src/sunstone\n</code></pre>"},{"location":"#linting-and-formatting","title":"Linting and Formatting","text":"<pre><code>uv run ruff check src/sunstone\nuv run ruff format src/sunstone\n</code></pre>"},{"location":"#about-sunstone-institute","title":"About Sunstone Institute","text":"<p>Sunstone Institute is a philanthropy-funded organization using data and AI to show the world as it really is, and inspire action everywhere.</p>"},{"location":"#license","title":"License","text":"<p>MIT License - see LICENSE file for details.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>Issues: GitHub Issues</li> </ul>"},{"location":"datapackage-extra-metadata/","title":"Data Package Metadata Extensibility","text":""},{"location":"datapackage-extra-metadata/#overview","title":"Overview","text":"<p>The Data Package standard provides excellent extensibility for augmenting descriptors with custom metadata, including semantic annotations from knowledge graphs, domain-specific properties, and organizational metadata.</p>"},{"location":"datapackage-extra-metadata/#custom-properties-with-namespaces","title":"Custom Properties with Namespaces","text":"<p>The Data Package specification supports custom properties using the <code>namespace:propertyName</code> convention. This allows you to add any metadata without conflicting with standard properties.</p>"},{"location":"datapackage-extra-metadata/#basic-example","title":"Basic Example","text":"<pre><code>{\n  \"name\": \"my-package\",\n  \"myorg:internal_id\": \"12345\",\n  \"myorg:department\": \"research\",\n  \"resources\": []\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#semantic-metadata-at-multiple-levels","title":"Semantic Metadata at Multiple Levels","text":"<p>Custom properties can be added at any level of the descriptor, making it ideal for semantic web integration and knowledge graph alignment.</p>"},{"location":"datapackage-extra-metadata/#1-package-level","title":"1. Package Level","text":"<p>Add semantic metadata to describe the entire dataset:</p> <pre><code>{\n  \"$schema\": \"https://datapackage.org/profiles/2.0/datapackage.json\",\n  \"name\": \"climate-observations\",\n  \"title\": \"Climate Observation Dataset\",\n  \"kg:ontology\": \"http://schema.org/Dataset\",\n  \"kg:subject\": [\n    \"http://dbpedia.org/resource/Climate_change\",\n    \"http://dbpedia.org/resource/Temperature\"\n  ],\n  \"kg:spatialCoverage\": \"http://sws.geonames.org/3144096/\",\n  \"schema:temporalCoverage\": \"2020-01-01/2024-12-31\",\n  \"resources\": [...]\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#2-resource-level","title":"2. Resource Level","text":"<p>Annotate individual data resources with semantic concepts:</p> <pre><code>{\n  \"resources\": [\n    {\n      \"name\": \"temperatures\",\n      \"path\": \"data/temperatures.csv\",\n      \"type\": \"table\",\n      \"kg:concept\": \"http://purl.obolibrary.org/obo/ENVO_01000267\",\n      \"kg:methodology\": \"http://example.org/methodology/automated-sensor\",\n      \"prov:wasGeneratedBy\": \"http://example.org/activity/sensor-collection-2024\",\n      \"schema\": {...}\n    }\n  ]\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#3-field-level-schema","title":"3. Field Level (Schema)","text":"<p>Add semantic annotations to individual fields for precise meaning:</p> <pre><code>{\n  \"schema\": {\n    \"fields\": [\n      {\n        \"name\": \"temperature\",\n        \"type\": \"number\",\n        \"title\": \"Air Temperature\",\n        \"kg:unit\": \"http://qudt.org/vocab/unit/DEG_C\",\n        \"kg:measuredProperty\": \"http://purl.obolibrary.org/obo/PATO_0000146\",\n        \"sosa:observedProperty\": \"http://example.org/property/air-temperature\",\n        \"constraints\": {\n          \"minimum\": -50,\n          \"maximum\": 50\n        }\n      },\n      {\n        \"name\": \"location_id\",\n        \"type\": \"string\",\n        \"kg:references\": \"http://www.geonames.org/\",\n        \"skos:exactMatch\": \"http://www.w3.org/2003/01/geo/wgs84_pos#SpatialThing\"\n      },\n      {\n        \"name\": \"species_code\",\n        \"type\": \"string\",\n        \"dwc:scientificName\": \"Taxonomic reference\",\n        \"kg:vocabulary\": \"http://rs.gbif.org/vocabulary/gbif/taxonomic_status.xml\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#common-use-cases","title":"Common Use Cases","text":""},{"location":"datapackage-extra-metadata/#1-knowledge-graph-integration","title":"1. Knowledge Graph Integration","text":"<p>Link datasets to ontologies and knowledge graphs:</p> <pre><code>{\n  \"name\": \"biodiversity-survey\",\n  \"kg:alignedOntology\": [\n    \"http://rs.tdwg.org/dwc/terms/\",\n    \"http://purl.obolibrary.org/obo/envo.owl\"\n  ],\n  \"schema:isBasedOn\": \"http://example.org/research/project/12345\",\n  \"resources\": [...]\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#2-provenance-tracking","title":"2. Provenance Tracking","text":"<p>Use W3C PROV vocabulary for data lineage:</p> <pre><code>{\n  \"name\": \"processed-data\",\n  \"prov:wasDerivedFrom\": \"http://example.org/dataset/raw-data\",\n  \"prov:wasGeneratedBy\": {\n    \"prov:activity\": \"data-cleaning-2024-01\",\n    \"prov:atTime\": \"2024-01-15T10:00:00Z\",\n    \"prov:wasAssociatedWith\": \"http://example.org/agent/data-team\"\n  },\n  \"resources\": [...]\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#3-domain-specific-metadata","title":"3. Domain-Specific Metadata","text":"<p>Add field-specific vocabularies for specialized domains:</p> <pre><code>{\n  \"schema\": {\n    \"fields\": [\n      {\n        \"name\": \"sample_id\",\n        \"type\": \"string\",\n        \"obi:hasURI\": \"http://purl.obolibrary.org/obo/OBI_0000066\",\n        \"lab:protocol\": \"http://example.org/protocols/sampling-v2\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#4-organizational-metadata","title":"4. Organizational Metadata","text":"<p>Internal tracking and workflow properties:</p> <pre><code>{\n  \"name\": \"my-dataset\",\n  \"myorg:project_id\": \"PRJ-2024-001\",\n  \"myorg:status\": \"approved\",\n  \"myorg:confidentiality\": \"internal\",\n  \"myorg:retention_period\": \"P7Y\",\n  \"myorg:owner\": \"research-team-alpha\",\n  \"resources\": [...]\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#recommended-namespace-prefixes","title":"Recommended Namespace Prefixes","text":"<p>Consider using established vocabulary prefixes for interoperability:</p> Prefix Namespace Purpose <code>kg:</code> Custom knowledge graph Your semantic annotations <code>schema:</code> http://schema.org/ Schema.org vocabulary <code>dcat:</code> http://www.w3.org/ns/dcat# Data Catalog Vocabulary <code>prov:</code> http://www.w3.org/ns/prov# Provenance Ontology <code>skos:</code> http://www.w3.org/2004/02/skos/core# Simple Knowledge Organization <code>dwc:</code> http://rs.tdwg.org/dwc/terms/ Darwin Core (biodiversity) <code>sosa:</code> http://www.w3.org/ns/sosa/ Sensor, Observation, Sample, Actuator <code>qudt:</code> http://qudt.org/schema/qudt/ Quantities, Units, Dimensions <code>obi:</code> http://purl.obolibrary.org/obo/OBI_ Ontology for Biomedical Investigations"},{"location":"datapackage-extra-metadata/#best-practices","title":"Best Practices","text":""},{"location":"datapackage-extra-metadata/#1-use-consistent-namespaces","title":"1. Use Consistent Namespaces","text":"<p>Choose a namespace prefix for your organization and use it consistently:</p> <pre><code>{\n  \"myorg:property1\": \"value\",\n  \"myorg:property2\": \"value\"\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#2-document-your-extensions","title":"2. Document Your Extensions","text":"<p>Add a README or separate documentation explaining your custom properties:</p> <pre><code>{\n  \"name\": \"my-dataset\",\n  \"myorg:metadata_version\": \"1.0\",\n  \"myorg:schema_documentation\": \"https://example.org/docs/metadata-schema\",\n  \"resources\": [...]\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#3-preserve-standard-properties","title":"3. Preserve Standard Properties","text":"<p>Never override or conflict with standard Data Package properties:</p> <pre><code>{\n  // Good: Custom property with namespace\n  \"myorg:title\": \"Internal title\",\n  \"title\": \"Public title\",\n\n  // Bad: Don't redefine standard properties\n  // \"resources\": \"something else\"\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#4-use-uris-for-semantic-references","title":"4. Use URIs for Semantic References","text":"<p>When linking to knowledge graphs, use full URIs:</p> <pre><code>{\n  \"kg:concept\": \"http://purl.obolibrary.org/obo/ENVO_01000267\",\n  // Not: \"kg:concept\": \"ENVO_01000267\"\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#5-validate-with-custom-profiles","title":"5. Validate with Custom Profiles","text":"<p>For strict validation of your extensions, create a custom profile:</p> <pre><code>{\n  \"$schema\": \"https://example.org/profiles/myorg-datapackage.json\",\n  \"name\": \"my-dataset\",\n  \"myorg:required_property\": \"value\",\n  \"resources\": [...]\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#complete-example-semantic-research-dataset","title":"Complete Example: Semantic Research Dataset","text":"<pre><code>{\n  \"$schema\": \"https://datapackage.org/profiles/2.0/datapackage.json\",\n  \"name\": \"ocean-temperature-study\",\n  \"title\": \"Ocean Temperature Observations 2020-2024\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Multi-year ocean temperature study from coastal monitoring stations\",\n\n  // Semantic metadata\n  \"schema:keywords\": [\"oceanography\", \"climate\", \"temperature\"],\n  \"dcat:theme\": [\"http://eurovoc.europa.eu/2107\"],\n  \"kg:ontology\": \"http://www.w3.org/ns/sosa/\",\n  \"kg:spatialCoverage\": \"http://sws.geonames.org/3144096/\",\n\n  // Provenance\n  \"prov:wasDerivedFrom\": \"http://example.org/dataset/raw-sensor-data\",\n  \"prov:wasGeneratedBy\": {\n    \"prov:activity\": \"quality-control-pipeline-v2\",\n    \"prov:atTime\": \"2024-01-15T10:00:00Z\"\n  },\n\n  // Organizational\n  \"myorg:project_id\": \"OCEAN-2024-001\",\n  \"myorg:funding_source\": \"NSF Grant #12345\",\n  \"myorg:data_classification\": \"public\",\n\n  \"licenses\": [{\n    \"name\": \"CC-BY-4.0\",\n    \"path\": \"https://creativecommons.org/licenses/by/4.0/\"\n  }],\n\n  \"resources\": [\n    {\n      \"name\": \"temperature-readings\",\n      \"type\": \"table\",\n      \"path\": \"data/temperatures.csv\",\n      \"title\": \"Temperature Observations\",\n\n      // Resource-level semantics\n      \"sosa:observationType\": \"http://example.org/observation/sea-surface-temperature\",\n      \"kg:instrumentType\": \"http://vocab.nerc.ac.uk/collection/L05/current/134/\",\n\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"timestamp\",\n            \"type\": \"datetime\",\n            \"title\": \"Observation Time\",\n            \"constraints\": {\"required\": true}\n          },\n          {\n            \"name\": \"station_id\",\n            \"type\": \"string\",\n            \"title\": \"Monitoring Station ID\",\n            \"kg:references\": \"http://example.org/stations/\",\n            \"constraints\": {\"required\": true}\n          },\n          {\n            \"name\": \"temperature\",\n            \"type\": \"number\",\n            \"title\": \"Sea Surface Temperature\",\n\n            // Field-level semantics\n            \"sosa:observedProperty\": \"http://vocab.nerc.ac.uk/collection/P07/current/CFSN0381/\",\n            \"qudt:unit\": \"http://qudt.org/vocab/unit/DEG_C\",\n            \"kg:measuredProperty\": \"http://purl.obolibrary.org/obo/PATO_0000146\",\n            \"skos:definition\": \"Temperature measured at 1 meter below sea surface\",\n\n            \"constraints\": {\n              \"required\": true,\n              \"minimum\": -2,\n              \"maximum\": 40\n            }\n          },\n          {\n            \"name\": \"depth_meters\",\n            \"type\": \"number\",\n            \"title\": \"Measurement Depth\",\n            \"qudt:unit\": \"http://qudt.org/vocab/unit/M\",\n            \"constraints\": {\"minimum\": 0}\n          },\n          {\n            \"name\": \"quality_flag\",\n            \"type\": \"integer\",\n            \"title\": \"QC Flag\",\n            \"myorg:qc_version\": \"v2.1\",\n            \"categories\": [\n              {\"value\": 0, \"label\": \"good\"},\n              {\"value\": 1, \"label\": \"suspect\"},\n              {\"value\": 2, \"label\": \"bad\"}\n            ]\n          }\n        ],\n        \"primaryKey\": [\"timestamp\", \"station_id\"]\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"datapackage-extra-metadata/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Any level is extensible - Add custom properties at package, resource, or field level</li> <li>Use namespaces - Prefix custom properties to avoid conflicts</li> <li>JSON flexibility - Custom properties can be strings, objects, arrays, etc.</li> <li>Standard tools preserve - Custom properties pass through standard Data Package tools</li> <li>Perfect for semantics - Ideal for linking to knowledge graphs, ontologies, and vocabularies</li> <li>No validation by default - Create custom profiles if you need validation of extensions</li> </ol> <p>This extensibility makes Data Package an excellent choice for FAIR data principles and semantic web integration while maintaining simplicity and interoperability.</p>"},{"location":"datapackage/","title":"Data Package Standard (v2)","text":""},{"location":"datapackage/#overview","title":"Overview","text":"<p>Data Package is a comprehensive data standard and data definition language (DDL) designed to improve data management, sharing, and interoperability. Version 2 of the standard provides a modernized framework for describing datasets that enhances the findability, accessibility, interoperability, and reusability (FAIR) of data.</p>"},{"location":"datapackage/#purpose","title":"Purpose","text":"<ul> <li>Create a standardized framework for describing datasets</li> <li>Provide a simple yet extensible data definition language</li> <li>Enable structured data packaging and delivery</li> <li>Facilitate easier data discovery and integration</li> <li>Support comprehensive dataset documentation</li> </ul>"},{"location":"datapackage/#design-philosophy","title":"Design Philosophy","text":"<ul> <li>Simple: Easy to understand and implement</li> <li>Extensible: Can be customized for specific use cases</li> <li>Language-agnostic: Works across different programming languages</li> <li>Interoperable: Compatible with existing data standards</li> <li>FAIR-focused: Promotes best practices in data management</li> </ul>"},{"location":"datapackage/#adoption","title":"Adoption","text":"<p>The Data Package standard is used by major organizations including: - European Commission - GitHub - GBIF (Global Biodiversity Information Facility) - Dryad - And many research institutions worldwide</p>"},{"location":"datapackage/#software-support","title":"Software Support","text":"<p>Open-source tools and libraries are available for multiple languages including Python, JavaScript, R, and more.</p>"},{"location":"datapackage/#architecture","title":"Architecture","text":"<p>The Data Package v2 standard consists of four core specifications that work together:</p> <ol> <li>Data Package: Container format for describing a coherent collection of data</li> <li>Data Resource: Format for describing individual data files or sources</li> <li>Table Schema: Detailed description of tabular data structure</li> <li>Table Dialect: Specification for how tabular data is physically stored</li> </ol>"},{"location":"datapackage/#key-concepts","title":"Key Concepts","text":""},{"location":"datapackage/#descriptor","title":"Descriptor","text":"<p>A descriptor is a JSON object that contains metadata about a data package, resource, or schema. Descriptors can: - Be stored in JSON files (e.g., <code>datapackage.json</code>) - Include custom properties using <code>namespace:propertyName</code> convention - Reference profiles for validation</p>"},{"location":"datapackage/#profile","title":"Profile","text":"<p>A profile is a URL that: - Resolves to a valid JSON Schema descriptor - Is versioned and immutable - Serves as a metadata version identifier - Enables validation of descriptors</p>"},{"location":"datapackage/#tabular-data","title":"Tabular Data","text":"<p>Tabular data consists of: - Rows with consistent fields - Optional header row defining field names - Multiple possible formats (CSV, Excel, JSON, databases, etc.)</p>"},{"location":"datapackage/#data-representation","title":"Data Representation","text":"<ul> <li>Physical representation: How data appears in files (text, binary, etc.)</li> <li>Logical representation: \"Ideal\" data with defined types and structures</li> </ul>"},{"location":"datapackage/#1-data-package-specification","title":"1. Data Package Specification","text":"<p>A Data Package is a simple container format for describing a coherent collection of data in a single package.</p>"},{"location":"datapackage/#requirements","title":"Requirements","text":"<ul> <li>MUST have a descriptor file (preferably named <code>datapackage.json</code>)</li> <li>MUST include at least one resource</li> <li>Descriptor contains metadata about the package and its resources</li> </ul>"},{"location":"datapackage/#required-properties","title":"Required Properties","text":"<ul> <li><code>resources</code> (array): List of data resources (REQUIRED)</li> </ul>"},{"location":"datapackage/#recommended-properties","title":"Recommended Properties","text":"<ul> <li><code>name</code>: Unique, human-readable identifier (lowercase alphanumeric)</li> <li><code>id</code>: Globally unique identifier (UUID, DOI, etc.)</li> <li><code>licenses</code>: Licensing information</li> <li><code>profile</code>: Profile URL for validation</li> </ul>"},{"location":"datapackage/#standard-properties","title":"Standard Properties","text":"Property Type Description <code>$schema</code> string Profile URL (default: <code>https://datapackage.org/profiles/2.0/datapackage.json</code>) <code>name</code> string Unique identifier, invariant across updates <code>id</code> string Globally unique identifier <code>title</code> string Human-readable title <code>description</code> string Detailed description (supports Markdown) <code>version</code> string Semantic version <code>created</code> string Creation datetime (ISO 8601) <code>homepage</code> string URL to package homepage <code>licenses</code> array License objects <code>sources</code> array Raw data source objects <code>contributors</code> array Contributor objects <code>keywords</code> array Search keywords <code>image</code> string Representative image URL <code>resources</code> array Data resource objects (REQUIRED)"},{"location":"datapackage/#example-minimal-data-package","title":"Example: Minimal Data Package","text":"<pre><code>{\n  \"name\": \"my-package\",\n  \"resources\": [\n    {\n      \"name\": \"my-data\",\n      \"path\": \"data.csv\"\n    }\n  ]\n}\n</code></pre>"},{"location":"datapackage/#example-complete-data-package","title":"Example: Complete Data Package","text":"<pre><code>{\n  \"$schema\": \"https://datapackage.org/profiles/2.0/datapackage.json\",\n  \"name\": \"gdp-data\",\n  \"title\": \"A nice title\",\n  \"version\": \"1.0.0\",\n  \"created\": \"1985-04-12T23:20:50.52Z\",\n  \"licenses\": [\n    {\n      \"name\": \"ODC-PDDL-1.0\",\n      \"path\": \"http://opendatacommons.org/licenses/pddl/\",\n      \"title\": \"Open Data Commons Public Domain Dedication and License v1.0\"\n    }\n  ],\n  \"sources\": [\n    {\n      \"title\": \"World Bank and OECD\",\n      \"path\": \"http://data.worldbank.org/indicator/NY.GDP.MKTP.CD\"\n    }\n  ],\n  \"contributors\": [\n    {\n      \"title\": \"Joe Bloggs\",\n      \"email\": \"[email protected]\",\n      \"path\": \"http://www.bloggs.com\",\n      \"roles\": [\"creator\"]\n    }\n  ],\n  \"resources\": [\n    {\n      \"name\": \"gdp\",\n      \"path\": \"data/gdp.csv\",\n      \"type\": \"table\",\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"country\",\n            \"type\": \"string\"\n          },\n          {\n            \"name\": \"year\",\n            \"type\": \"integer\"\n          },\n          {\n            \"name\": \"gdp\",\n            \"type\": \"number\"\n          }\n        ]\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"datapackage/#file-structure","title":"File Structure","text":"<p>A typical Data Package directory structure:</p> <pre><code>my-package/\n\u251c\u2500\u2500 datapackage.json\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 mydata.csv\n\u2502   \u2514\u2500\u2500 otherdata.csv\n\u2514\u2500\u2500 scripts/\n    \u2514\u2500\u2500 process.py\n</code></pre>"},{"location":"datapackage/#2-data-resource-specification","title":"2. Data Resource Specification","text":"<p>A Data Resource describes and packages a single data resource, such as an individual table or file.</p>"},{"location":"datapackage/#purpose_1","title":"Purpose","text":"<p>Provide a locator for data with optional rich metadata.</p>"},{"location":"datapackage/#required-properties_1","title":"Required Properties","text":"<ul> <li><code>name</code>: Unique identifier within the package (lowercase alphanumeric)</li> </ul>"},{"location":"datapackage/#data-location-one-required","title":"Data Location (one required)","text":"<ul> <li><code>path</code>: URL or file system path to data file(s)</li> <li><code>data</code>: Inline data representation</li> </ul>"},{"location":"datapackage/#recommended-properties_1","title":"Recommended Properties","text":"<ul> <li><code>type</code>: Resource type (e.g., <code>table</code> for tabular data)</li> <li><code>title</code>: Human-readable label</li> <li><code>description</code>: Detailed description</li> <li><code>format</code>: File extension (e.g., <code>csv</code>, <code>json</code>, <code>xlsx</code>)</li> <li><code>mediatype</code>: MIME type (e.g., <code>text/csv</code>)</li> <li><code>encoding</code>: Character encoding (e.g., <code>utf-8</code>)</li> </ul>"},{"location":"datapackage/#tabular-data-properties","title":"Tabular Data Properties","text":"<p>When <code>type</code> is <code>table</code>: - <code>schema</code>: Table Schema describing structure - <code>dialect</code>: Table Dialect describing physical format</p>"},{"location":"datapackage/#path-property","title":"Path Property","text":"<p>The <code>path</code> property can be: - A single file: <code>\"path\": \"data.csv\"</code> - Multiple files: <code>\"path\": [\"data1.csv\", \"data2.csv\"]</code> - A URL: <code>\"path\": \"http://example.com/data.csv\"</code> - A relative POSIX path: <code>\"path\": \"data/myfile.csv\"</code></p> <p>Security restrictions: - Cannot use absolute paths (<code>/path/to/file</code>) - Cannot use parent paths (<code>../file</code>) - Cannot reference hidden folders</p>"},{"location":"datapackage/#example-basic-resource","title":"Example: Basic Resource","text":"<pre><code>{\n  \"name\": \"solar-system\",\n  \"path\": \"http://example.com/solar-system.csv\",\n  \"title\": \"The Solar System\",\n  \"format\": \"csv\",\n  \"mediatype\": \"text/csv\",\n  \"encoding\": \"utf-8\"\n}\n</code></pre>"},{"location":"datapackage/#example-tabular-resource-with-schema","title":"Example: Tabular Resource with Schema","text":"<pre><code>{\n  \"name\": \"population\",\n  \"type\": \"table\",\n  \"path\": \"data/population.csv\",\n  \"title\": \"Population Data\",\n  \"format\": \"csv\",\n  \"schema\": {\n    \"fields\": [\n      {\n        \"name\": \"country\",\n        \"type\": \"string\"\n      },\n      {\n        \"name\": \"population\",\n        \"type\": \"integer\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"datapackage/#example-inline-data","title":"Example: Inline Data","text":"<pre><code>{\n  \"name\": \"countries\",\n  \"data\": [\n    {\"code\": \"US\", \"name\": \"United States\"},\n    {\"code\": \"GB\", \"name\": \"United Kingdom\"},\n    {\"code\": \"NO\", \"name\": \"Norway\"}\n  ]\n}\n</code></pre>"},{"location":"datapackage/#example-multiple-files","title":"Example: Multiple Files","text":"<pre><code>{\n  \"name\": \"annual-reports\",\n  \"path\": [\n    \"data/2020.csv\",\n    \"data/2021.csv\",\n    \"data/2022.csv\"\n  ],\n  \"format\": \"csv\"\n}\n</code></pre>"},{"location":"datapackage/#3-table-schema-specification","title":"3. Table Schema Specification","text":"<p>Table Schema is a format for declaring schemas for tabular data, providing type checking and validation capabilities.</p>"},{"location":"datapackage/#core-properties","title":"Core Properties","text":"Property Type Description <code>fields</code> array Field descriptors (REQUIRED) <code>$schema</code> string Profile URL <code>missingValues</code> array Defines how missing values are represented <code>primaryKey</code> string/array Unique row identifier(s) <code>foreignKeys</code> array Links between tables"},{"location":"datapackage/#field-properties","title":"Field Properties","text":"<p>Each field in the <code>fields</code> array has:</p> Property Type Description <code>name</code> string Field name (REQUIRED) <code>type</code> string Data type (recommended) <code>format</code> string Specific format for the type <code>title</code> string Human-readable title <code>description</code> string Field description <code>example</code> any Example value <code>constraints</code> object Validation rules <code>categories</code> array Categorical values with labels <code>categoriesOrdered</code> boolean Whether categories have order"},{"location":"datapackage/#field-types","title":"Field Types","text":"Type Description Example <code>string</code> Text data \"Hello World\" <code>number</code> Decimal numbers 3.14, -42.5 <code>integer</code> Whole numbers 42, -17 <code>boolean</code> True/false true, false <code>date</code> Calendar date 2024-01-15 <code>datetime</code> Date and time 2024-01-15T10:30:00Z <code>time</code> Time of day 10:30:00 <code>year</code> Year 2024 <code>yearmonth</code> Year and month 2024-01 <code>duration</code> Time duration P1Y2M (ISO 8601) <code>geopoint</code> Geographic coordinates [45.5231, -122.6765] <code>geojson</code> GeoJSON geometry {...} <code>object</code> JSON object {\"key\": \"value\"} <code>array</code> JSON array [1, 2, 3] <code>any</code> Unspecified/mixed type any value"},{"location":"datapackage/#field-constraints","title":"Field Constraints","text":"Constraint Type Description <code>required</code> boolean Field cannot be null <code>unique</code> boolean All values must be unique <code>minLength</code> integer Minimum string length <code>maxLength</code> integer Maximum string length <code>minimum</code> number Minimum value <code>maximum</code> number Maximum value <code>pattern</code> string Regular expression validation <code>enum</code> array Restrict to specific values"},{"location":"datapackage/#example-basic-table-schema","title":"Example: Basic Table Schema","text":"<pre><code>{\n  \"fields\": [\n    {\n      \"name\": \"id\",\n      \"type\": \"integer\"\n    },\n    {\n      \"name\": \"name\",\n      \"type\": \"string\"\n    },\n    {\n      \"name\": \"price\",\n      \"type\": \"number\"\n    }\n  ]\n}\n</code></pre>"},{"location":"datapackage/#example-schema-with-constraints","title":"Example: Schema with Constraints","text":"<pre><code>{\n  \"fields\": [\n    {\n      \"name\": \"id\",\n      \"type\": \"integer\",\n      \"constraints\": {\n        \"required\": true,\n        \"unique\": true\n      }\n    },\n    {\n      \"name\": \"email\",\n      \"type\": \"string\",\n      \"format\": \"email\",\n      \"constraints\": {\n        \"required\": true\n      }\n    },\n    {\n      \"name\": \"price\",\n      \"type\": \"integer\",\n      \"constraints\": {\n        \"minimum\": 100,\n        \"maximum\": 150,\n        \"required\": true\n      }\n    }\n  ],\n  \"primaryKey\": \"id\"\n}\n</code></pre>"},{"location":"datapackage/#example-categories","title":"Example: Categories","text":"<p>Categories allow you to define labeled values, useful for coded data:</p> <pre><code>{\n  \"fields\": [\n    {\n      \"name\": \"fruit\",\n      \"type\": \"integer\",\n      \"categories\": [\n        {\"value\": 0, \"label\": \"apple\"},\n        {\"value\": 1, \"label\": \"orange\"},\n        {\"value\": 2, \"label\": \"banana\"}\n      ],\n      \"categoriesOrdered\": true\n    }\n  ]\n}\n</code></pre>"},{"location":"datapackage/#example-foreign-keys","title":"Example: Foreign Keys","text":"<p>Foreign keys create relationships between tables:</p> <pre><code>{\n  \"resources\": [\n    {\n      \"name\": \"population-by-state\",\n      \"schema\": {\n        \"fields\": [\n          {\"name\": \"state-code\", \"type\": \"string\"},\n          {\"name\": \"population\", \"type\": \"integer\"}\n        ],\n        \"foreignKeys\": [\n          {\n            \"fields\": [\"state-code\"],\n            \"reference\": {\n              \"resource\": \"state-codes\",\n              \"fields\": [\"code\"]\n            }\n          }\n        ]\n      }\n    },\n    {\n      \"name\": \"state-codes\",\n      \"schema\": {\n        \"fields\": [\n          {\"name\": \"code\", \"type\": \"string\"},\n          {\"name\": \"name\", \"type\": \"string\"}\n        ],\n        \"primaryKey\": \"code\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"datapackage/#example-missing-values","title":"Example: Missing Values","text":"<p>Define how missing or null values are represented:</p> <pre><code>{\n  \"fields\": [\n    {\"name\": \"temperature\", \"type\": \"number\"},\n    {\"name\": \"notes\", \"type\": \"string\"}\n  ],\n  \"missingValues\": [\n    {\"value\": \"\", \"label\": \"OMITTED\"},\n    {\"value\": \"-99\", \"label\": \"REFUSED\"},\n    {\"value\": \"N/A\", \"label\": \"NOT_APPLICABLE\"}\n  ]\n}\n</code></pre>"},{"location":"datapackage/#4-table-dialect-specification","title":"4. Table Dialect Specification","text":"<p>Table Dialect describes how tabular data is physically stored in a file, supporting various formats like CSV, TSV, JSON, Excel, and databases.</p>"},{"location":"datapackage/#purpose_2","title":"Purpose","text":"<ul> <li>Define parsing rules for tabular data files</li> <li>Ensure data interoperability across different formats</li> <li>Provide configuration for delimiters, quotes, line terminators, etc.</li> </ul>"},{"location":"datapackage/#standard-properties_1","title":"Standard Properties","text":"Property Type Default Description <code>$schema</code> string - Profile URL <code>header</code> boolean <code>true</code> Whether first row contains field names <code>headerRows</code> array <code>[1]</code> Row numbers containing headers <code>delimiter</code> string <code>,</code> Field delimiter character <code>lineTerminator</code> string <code>\\r\\n</code> Row separator <code>quoteChar</code> string <code>\"</code> Quote character <code>doubleQuote</code> boolean <code>true</code> Whether quotes are escaped by doubling <code>escapeChar</code> string - Escape character (alternative to doubleQuote) <code>skipInitialSpace</code> boolean <code>false</code> Ignore whitespace after delimiter <code>commentChar</code> string - Comment line prefix <code>caseSensitiveHeader</code> boolean <code>false</code> Whether header names are case-sensitive"},{"location":"datapackage/#supported-formats","title":"Supported Formats","text":"<p>The Table Dialect specification supports: - Delimited formats: CSV, TSV, pipe-delimited - Structured formats: JSON, YAML - Spreadsheets: Excel (.xlsx, .xls), OpenOffice (.ods) - Databases: SQL tables, query results</p>"},{"location":"datapackage/#example-semicolon-delimited-csv","title":"Example: Semicolon-Delimited CSV","text":"<pre><code>{\n  \"delimiter\": \";\",\n  \"quoteChar\": \"'\",\n  \"header\": true\n}\n</code></pre>"},{"location":"datapackage/#example-tab-delimited-with-comments","title":"Example: Tab-Delimited with Comments","text":"<pre><code>{\n  \"delimiter\": \"\\t\",\n  \"lineTerminator\": \"\\n\",\n  \"commentChar\": \"#\",\n  \"header\": true\n}\n</code></pre>"},{"location":"datapackage/#example-no-header-row","title":"Example: No Header Row","text":"<pre><code>{\n  \"header\": false,\n  \"delimiter\": \",\",\n  \"quoteChar\": \"\\\"\"\n}\n</code></pre>"},{"location":"datapackage/#example-custom-quote-escaping","title":"Example: Custom Quote Escaping","text":"<pre><code>{\n  \"delimiter\": \",\",\n  \"quoteChar\": \"\\\"\",\n  \"doubleQuote\": false,\n  \"escapeChar\": \"\\\\\"\n}\n</code></pre>"},{"location":"datapackage/#example-multiline-headers","title":"Example: Multiline Headers","text":"<pre><code>{\n  \"headerRows\": [1, 2],\n  \"delimiter\": \",\"\n}\n</code></pre>"},{"location":"datapackage/#important-notes","title":"Important Notes","text":"<ul> <li>Table Dialect focuses on formatting, not data types or schema</li> <li>Character encoding is handled separately (not part of dialect)</li> <li>Backward compatible with the older \"CSV Dialect\" specification</li> <li>Orthogonal to Table Schema (they work together but are independent)</li> </ul>"},{"location":"datapackage/#complete-example-multi-resource-package","title":"Complete Example: Multi-Resource Package","text":"<p>Here's a comprehensive example showing all specifications working together:</p> <p>datapackage.json:</p> <pre><code>{\n  \"$schema\": \"https://datapackage.org/profiles/2.0/datapackage.json\",\n  \"name\": \"population-and-cities\",\n  \"title\": \"Country Population and Major Cities\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Population data by country with major cities information\",\n  \"created\": \"2024-01-15T10:00:00Z\",\n  \"licenses\": [\n    {\n      \"name\": \"CC-BY-4.0\",\n      \"title\": \"Creative Commons Attribution 4.0\",\n      \"path\": \"https://creativecommons.org/licenses/by/4.0/\"\n    }\n  ],\n  \"contributors\": [\n    {\n      \"title\": \"Data Team\",\n      \"email\": \"[email protected]\",\n      \"roles\": [\"author\", \"maintainer\"]\n    }\n  ],\n  \"keywords\": [\"population\", \"demographics\", \"cities\"],\n  \"resources\": [\n    {\n      \"name\": \"countries\",\n      \"type\": \"table\",\n      \"path\": \"data/countries.csv\",\n      \"title\": \"Country Population Data\",\n      \"format\": \"csv\",\n      \"mediatype\": \"text/csv\",\n      \"encoding\": \"utf-8\",\n      \"dialect\": {\n        \"delimiter\": \",\",\n        \"header\": true,\n        \"quoteChar\": \"\\\"\"\n      },\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"country_code\",\n            \"type\": \"string\",\n            \"title\": \"ISO Country Code\",\n            \"constraints\": {\n              \"required\": true,\n              \"unique\": true,\n              \"pattern\": \"^[A-Z]{2}$\"\n            }\n          },\n          {\n            \"name\": \"country_name\",\n            \"type\": \"string\",\n            \"title\": \"Country Name\",\n            \"constraints\": {\n              \"required\": true\n            }\n          },\n          {\n            \"name\": \"population\",\n            \"type\": \"integer\",\n            \"title\": \"Total Population\",\n            \"constraints\": {\n              \"minimum\": 0\n            }\n          },\n          {\n            \"name\": \"area_km2\",\n            \"type\": \"number\",\n            \"title\": \"Area in km\u00b2\"\n          },\n          {\n            \"name\": \"last_updated\",\n            \"type\": \"date\"\n          }\n        ],\n        \"primaryKey\": \"country_code\",\n        \"missingValues\": [\n          {\"value\": \"\", \"label\": \"NOT_PROVIDED\"},\n          {\"value\": \"N/A\", \"label\": \"NOT_APPLICABLE\"}\n        ]\n      }\n    },\n    {\n      \"name\": \"cities\",\n      \"type\": \"table\",\n      \"path\": \"data/cities.csv\",\n      \"title\": \"Major Cities\",\n      \"format\": \"csv\",\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"city_id\",\n            \"type\": \"integer\",\n            \"constraints\": {\n              \"required\": true,\n              \"unique\": true\n            }\n          },\n          {\n            \"name\": \"city_name\",\n            \"type\": \"string\",\n            \"constraints\": {\n              \"required\": true\n            }\n          },\n          {\n            \"name\": \"country_code\",\n            \"type\": \"string\",\n            \"constraints\": {\n              \"required\": true,\n              \"pattern\": \"^[A-Z]{2}$\"\n            }\n          },\n          {\n            \"name\": \"population\",\n            \"type\": \"integer\",\n            \"constraints\": {\n              \"minimum\": 0\n            }\n          },\n          {\n            \"name\": \"coordinates\",\n            \"type\": \"geopoint\",\n            \"title\": \"City Coordinates\"\n          }\n        ],\n        \"primaryKey\": \"city_id\",\n        \"foreignKeys\": [\n          {\n            \"fields\": [\"country_code\"],\n            \"reference\": {\n              \"resource\": \"countries\",\n              \"fields\": [\"country_code\"]\n            }\n          }\n        ]\n      }\n    },\n    {\n      \"name\": \"regions\",\n      \"title\": \"World Regions Lookup\",\n      \"data\": [\n        {\"code\": \"EU\", \"name\": \"Europe\"},\n        {\"code\": \"AS\", \"name\": \"Asia\"},\n        {\"code\": \"AF\", \"name\": \"Africa\"},\n        {\"code\": \"NA\", \"name\": \"North America\"},\n        {\"code\": \"SA\", \"name\": \"South America\"},\n        {\"code\": \"OC\", \"name\": \"Oceania\"}\n      ],\n      \"schema\": {\n        \"fields\": [\n          {\"name\": \"code\", \"type\": \"string\"},\n          {\"name\": \"name\", \"type\": \"string\"}\n        ],\n        \"primaryKey\": \"code\"\n      }\n    }\n  ]\n}\n</code></pre> <p>This example demonstrates: - Multiple resources (CSV files and inline data) - Complete metadata (licenses, contributors, keywords) - Detailed table schemas with various field types - Constraints and validation rules - Primary and foreign keys for referential integrity - Table dialect specification for CSV parsing - Missing value definitions</p>"},{"location":"datapackage/#advanced-features","title":"Advanced Features","text":""},{"location":"datapackage/#custom-properties","title":"Custom Properties","text":"<p>Descriptors can include custom properties using namespace conventions:</p> <pre><code>{\n  \"name\": \"my-package\",\n  \"myorg:internal_id\": \"12345\",\n  \"myorg:department\": \"research\",\n  \"resources\": [ ]\n}\n</code></pre>"},{"location":"datapackage/#resource-caching","title":"Resource Caching","text":"<p>The <code>_cache</code> property provides fallback locations when primary data sources are unavailable:</p> <pre><code>{\n  \"name\": \"remote-data\",\n  \"path\": \"https://example.com/data.csv\",\n  \"_cache\": \"cache/data.csv\"\n}\n</code></pre>"},{"location":"datapackage/#profiles","title":"Profiles","text":"<p>Specify custom profiles for validation:</p> <pre><code>{\n  \"profile\": \"https://example.com/profiles/custom-package.json\",\n  \"name\": \"my-package\",\n  \"resources\": [ ]\n}\n</code></pre>"},{"location":"datapackage/#benefits-and-use-cases","title":"Benefits and Use Cases","text":""},{"location":"datapackage/#benefits","title":"Benefits","text":"<ol> <li>FAIR Data Principles: Enhances findability, accessibility, interoperability, and reusability</li> <li>Self-Describing: Metadata travels with data</li> <li>Validation: Schemas enable automatic validation</li> <li>Standardization: Consistent format across organizations</li> <li>Documentation: Built-in comprehensive metadata</li> <li>Versioning: Track changes and evolution</li> <li>Relationships: Foreign keys enable data linking</li> <li>Type Safety: Strong typing for data fields</li> </ol>"},{"location":"datapackage/#use-cases","title":"Use Cases","text":"<ul> <li>Research Data Management: Package research datasets with complete provenance</li> <li>Open Data Publishing: Government and public sector data sharing</li> <li>Data Integration: ETL pipelines with standardized formats</li> <li>Data Catalogs: Build searchable data repositories</li> <li>Data Quality: Validate data against schemas</li> <li>Collaborative Projects: Share data with clear documentation</li> <li>Archival: Long-term data preservation with metadata</li> </ul>"},{"location":"datapackage/#tools-and-software","title":"Tools and Software","text":"<p>The Data Package ecosystem includes:</p> <ul> <li>Open Data Editor: Visual tool for creating and editing data packages</li> <li>Frictionless Framework (Python): Create, validate, and transform packages</li> <li>JavaScript libraries: Browser and Node.js support</li> <li>R packages: Integration with R workflows</li> <li>Command-line tools: Automation and scripting</li> </ul>"},{"location":"datapackage/#comparison-with-v1","title":"Comparison with v1","text":"<p>Data Package v2 builds on v1 with improvements including:</p> <ul> <li>Enhanced Table Schema with categories and ordered categories</li> <li>More flexible missing values with labels</li> <li>Table Dialect specification (evolved from CSV Dialect)</li> <li>Better profile system for validation</li> <li>Improved foreign key definitions</li> <li>Extended metadata properties</li> </ul>"},{"location":"datapackage/#references","title":"References","text":"<ul> <li>Official Website: https://datapackage.org/</li> <li>Specifications:</li> <li>Data Package: https://datapackage.org/standard/data-package/</li> <li>Data Resource: https://datapackage.org/standard/data-resource/</li> <li>Table Schema: https://datapackage.org/standard/table-schema/</li> <li>Table Dialect: https://datapackage.org/standard/table-dialect/</li> <li>GitHub: https://github.com/frictionlessdata</li> <li>Open Knowledge Foundation: https://okfn.org/</li> </ul>"},{"location":"datapackage/#related-standards","title":"Related Standards","text":"<p>Data Package v2 is inspired by and compatible with: - DataCite - Zenodo - DCAT (Data Catalog Vocabulary) - CKAN - Schema.org</p>"},{"location":"frictionlessdata/","title":"Frictionless Data Standard","text":""},{"location":"frictionlessdata/#overview","title":"Overview","text":"<p>Frictionless Data is an open-source toolkit and set of specifications designed to simplify data management, integration, and sharing. It brings simplicity to the data experience by standardizing how data is packaged, described, and distributed.</p>"},{"location":"frictionlessdata/#purpose","title":"Purpose","text":"<ul> <li>Make data reproducible, processable, and standardizable</li> <li>Handle everything from simple CSV files to complex data pipelines</li> <li>Promote FAIR principles: Findable, Accessible, Interoperable, Reusable</li> <li>Create reliable, repeatable, and automated data integration workflows</li> </ul>"},{"location":"frictionlessdata/#design-philosophy","title":"Design Philosophy","text":"<ul> <li>Approachable: Minimal core with simple concepts</li> <li>Incrementally Adoptable: Start small and scale as needed</li> <li>Progressive: Enhances existing tools and workflows</li> <li>Simplicity: Easy to understand and implement</li> <li>Extensibility: Can be extended for specific use cases</li> <li>Cross-technology: Works across different platforms and languages</li> </ul>"},{"location":"frictionlessdata/#target-users","title":"Target Users","text":"<ul> <li>Researchers</li> <li>Data Scientists</li> <li>Data Engineers</li> <li>Anyone working with structured data</li> </ul>"},{"location":"frictionlessdata/#core-concepts","title":"Core Concepts","text":""},{"location":"frictionlessdata/#1-data-packaging","title":"1. Data Packaging","text":"<p>Bundle data files with metadata and schemas to provide clarity and context. This makes data self-describing and easier to understand and use.</p>"},{"location":"frictionlessdata/#2-data-transformation","title":"2. Data Transformation","text":"<p>Clean and convert data between formats with standardized processes.</p>"},{"location":"frictionlessdata/#3-data-storageintegration","title":"3. Data Storage/Integration","text":"<p>Push data into different platforms and applications using consistent formats and metadata.</p>"},{"location":"frictionlessdata/#main-specifications","title":"Main Specifications","text":"<p>The Frictionless Data standard is composed of several modular specifications that work together:</p>"},{"location":"frictionlessdata/#1-data-package","title":"1. Data Package","text":""},{"location":"frictionlessdata/#2-data-resource","title":"2. Data Resource","text":""},{"location":"frictionlessdata/#3-table-schema","title":"3. Table Schema","text":"<p>Additional specifications include CSV Dialect, Tabular Data Package, Fiscal Data Package, and more.</p>"},{"location":"frictionlessdata/#1-data-package_1","title":"1. Data Package","text":"<p>A Data Package is a simple container format for describing and distributing a collection of data.</p>"},{"location":"frictionlessdata/#structure","title":"Structure","text":"<p>A Data Package is centered around a <code>datapackage.json</code> descriptor file placed in the top-level directory.</p>"},{"location":"frictionlessdata/#required-properties","title":"Required Properties","text":"<ul> <li><code>resources</code> (array): List of data resources in the package (REQUIRED)</li> </ul>"},{"location":"frictionlessdata/#recommended-properties","title":"Recommended Properties","text":"<ul> <li><code>name</code>: Unique, URL-friendly identifier (lowercase, alphanumeric, hyphens, underscores)</li> <li><code>id</code>: Globally unique identifier (UUID or DOI)</li> <li><code>licenses</code>: Licensing information</li> <li><code>profile</code>: Specification profile being used</li> </ul>"},{"location":"frictionlessdata/#optional-properties","title":"Optional Properties","text":"<ul> <li><code>title</code>: Human-readable title</li> <li><code>description</code>: Detailed description (supports Markdown)</li> <li><code>version</code>: Semantic version string</li> <li><code>sources</code>: Information about raw data origins</li> <li><code>contributors</code>: People or organizations involved</li> <li><code>keywords</code>: Array of tags for searchability</li> <li><code>image</code>: Representative image URL</li> </ul>"},{"location":"frictionlessdata/#example-minimal-data-package","title":"Example: Minimal Data Package","text":"<pre><code>{\n  \"name\": \"my-dataset\",\n  \"resources\": [\n    {\n      \"path\": \"data.csv\",\n      \"title\": \"My Data\"\n    }\n  ]\n}\n</code></pre>"},{"location":"frictionlessdata/#example-complete-data-package","title":"Example: Complete Data Package","text":"<pre><code>{\n  \"name\": \"global-temperature-data\",\n  \"title\": \"Global Temperature Data 1880-2020\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Historical global temperature measurements from weather stations worldwide.\",\n  \"licenses\": [\n    {\n      \"name\": \"CC-BY-4.0\",\n      \"path\": \"https://creativecommons.org/licenses/by/4.0/\",\n      \"title\": \"Creative Commons Attribution 4.0\"\n    }\n  ],\n  \"sources\": [\n    {\n      \"title\": \"NOAA Climate Data\",\n      \"path\": \"https://www.noaa.gov/climate-data\"\n    }\n  ],\n  \"contributors\": [\n    {\n      \"title\": \"Jane Doe\",\n      \"role\": \"author\",\n      \"email\": \"jane@example.com\"\n    }\n  ],\n  \"keywords\": [\"climate\", \"temperature\", \"weather\"],\n  \"resources\": [\n    {\n      \"name\": \"temperature-readings\",\n      \"path\": \"data/temperatures.csv\",\n      \"title\": \"Temperature Readings\",\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"station_id\",\n            \"type\": \"string\"\n          },\n          {\n            \"name\": \"date\",\n            \"type\": \"date\"\n          },\n          {\n            \"name\": \"temperature\",\n            \"type\": \"number\"\n          }\n        ]\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"frictionlessdata/#2-data-resource_1","title":"2. Data Resource","text":"<p>A Data Resource describes a single data file or data source (like an individual table or file).</p>"},{"location":"frictionlessdata/#required-properties_1","title":"Required Properties","text":"<ul> <li><code>name</code>: Unique identifier (lowercase alphanumeric, periods, hyphens, underscores)</li> </ul>"},{"location":"frictionlessdata/#data-location-choose-one","title":"Data Location (choose one)","text":"<ul> <li><code>path</code>: Path to file (local relative path or remote URL)</li> <li><code>data</code>: Inline data within the descriptor</li> </ul>"},{"location":"frictionlessdata/#optional-properties_1","title":"Optional Properties","text":"<ul> <li><code>title</code>: Human-readable name</li> <li><code>description</code>: Detailed description</li> <li><code>format</code>: File format (e.g., 'csv', 'json', 'xlsx')</li> <li><code>mediatype</code>: MIME type (e.g., 'text/csv')</li> <li><code>encoding</code>: Character encoding (e.g., 'utf-8')</li> <li><code>schema</code>: Data structure description (often a Table Schema)</li> </ul>"},{"location":"frictionlessdata/#example-resource-with-path","title":"Example: Resource with Path","text":"<pre><code>{\n  \"name\": \"sales-data\",\n  \"title\": \"Sales Data Q1 2024\",\n  \"path\": \"data/sales-q1-2024.csv\",\n  \"format\": \"csv\",\n  \"mediatype\": \"text/csv\",\n  \"encoding\": \"utf-8\",\n  \"description\": \"Quarterly sales data including revenue, units sold, and region.\"\n}\n</code></pre>"},{"location":"frictionlessdata/#example-resource-with-inline-data","title":"Example: Resource with Inline Data","text":"<pre><code>{\n  \"name\": \"countries\",\n  \"title\": \"Country Codes\",\n  \"data\": [\n    {\"code\": \"US\", \"name\": \"United States\"},\n    {\"code\": \"GB\", \"name\": \"United Kingdom\"},\n    {\"code\": \"NO\", \"name\": \"Norway\"}\n  ]\n}\n</code></pre>"},{"location":"frictionlessdata/#example-resource-with-remote-url","title":"Example: Resource with Remote URL","text":"<pre><code>{\n  \"name\": \"population-data\",\n  \"path\": \"https://example.com/data/population-2024.csv\",\n  \"format\": \"csv\",\n  \"schema\": {\n    \"fields\": [\n      {\"name\": \"country\", \"type\": \"string\"},\n      {\"name\": \"year\", \"type\": \"integer\"},\n      {\"name\": \"population\", \"type\": \"integer\"}\n    ]\n  }\n}\n</code></pre>"},{"location":"frictionlessdata/#3-table-schema_1","title":"3. Table Schema","text":"<p>Table Schema is a language-agnostic specification for defining the structure of tabular data. It provides detailed descriptions of fields, types, and constraints.</p>"},{"location":"frictionlessdata/#structure_1","title":"Structure","text":"<pre><code>{\n  \"fields\": [ ... ],\n  \"primaryKey\": \"field_name\" or [\"field1\", \"field2\"],\n  \"foreignKeys\": [ ... ],\n  \"missingValues\": [\"\"]\n}\n</code></pre>"},{"location":"frictionlessdata/#field-properties","title":"Field Properties","text":"<p>Each field in the <code>fields</code> array has:</p> <ul> <li><code>name</code> (required): Field name</li> <li><code>type</code> (recommended): Data type</li> <li><code>format</code>: Specific format for the type</li> <li><code>title</code>: Human-readable title</li> <li><code>description</code>: Field description</li> <li><code>constraints</code>: Validation rules</li> </ul>"},{"location":"frictionlessdata/#field-types","title":"Field Types","text":"Type Description Example <code>string</code> Text data \"Hello World\" <code>number</code> Numeric data (int or float) 3.14, 42 <code>integer</code> Whole numbers 42 <code>boolean</code> True/false values true, false <code>date</code> Date values 2024-01-15 <code>datetime</code> Date and time 2024-01-15T10:30:00Z <code>time</code> Time values 10:30:00 <code>year</code> Year values 2024 <code>object</code> JSON object {\"key\": \"value\"} <code>array</code> JSON array [1, 2, 3] <code>geopoint</code> Geographic coordinates [45.5231, -122.6765] <code>geojson</code> GeoJSON data {...}"},{"location":"frictionlessdata/#field-constraints","title":"Field Constraints","text":"<ul> <li><code>required</code> (boolean): Field cannot be null/missing</li> <li><code>unique</code> (boolean): All values must be unique</li> <li><code>minLength</code> / <code>maxLength</code> (integer): String length constraints</li> <li><code>minimum</code> / <code>maximum</code> (number): Numeric range constraints</li> <li><code>pattern</code> (string): Regular expression validation</li> <li><code>enum</code> (array): Restrict to specific allowed values</li> </ul>"},{"location":"frictionlessdata/#example-basic-table-schema","title":"Example: Basic Table Schema","text":"<pre><code>{\n  \"fields\": [\n    {\n      \"name\": \"id\",\n      \"type\": \"integer\",\n      \"title\": \"User ID\",\n      \"constraints\": {\n        \"required\": true,\n        \"unique\": true\n      }\n    },\n    {\n      \"name\": \"name\",\n      \"type\": \"string\",\n      \"title\": \"Full Name\",\n      \"constraints\": {\n        \"required\": true,\n        \"minLength\": 2,\n        \"maxLength\": 100\n      }\n    },\n    {\n      \"name\": \"age\",\n      \"type\": \"integer\",\n      \"title\": \"Age\",\n      \"constraints\": {\n        \"minimum\": 0,\n        \"maximum\": 120\n      }\n    },\n    {\n      \"name\": \"email\",\n      \"type\": \"string\",\n      \"format\": \"email\",\n      \"constraints\": {\n        \"required\": true\n      }\n    },\n    {\n      \"name\": \"status\",\n      \"type\": \"string\",\n      \"constraints\": {\n        \"enum\": [\"active\", \"inactive\", \"pending\"]\n      }\n    }\n  ],\n  \"primaryKey\": \"id\",\n  \"missingValues\": [\"\", \"N/A\", \"null\"]\n}\n</code></pre>"},{"location":"frictionlessdata/#example-advanced-table-schema-with-foreign-keys","title":"Example: Advanced Table Schema with Foreign Keys","text":"<pre><code>{\n  \"fields\": [\n    {\n      \"name\": \"order_id\",\n      \"type\": \"integer\",\n      \"constraints\": {\n        \"required\": true,\n        \"unique\": true\n      }\n    },\n    {\n      \"name\": \"customer_id\",\n      \"type\": \"integer\",\n      \"constraints\": {\n        \"required\": true\n      }\n    },\n    {\n      \"name\": \"order_date\",\n      \"type\": \"date\",\n      \"format\": \"default\",\n      \"constraints\": {\n        \"required\": true\n      }\n    },\n    {\n      \"name\": \"total_amount\",\n      \"type\": \"number\",\n      \"constraints\": {\n        \"minimum\": 0\n      }\n    }\n  ],\n  \"primaryKey\": \"order_id\",\n  \"foreignKeys\": [\n    {\n      \"fields\": \"customer_id\",\n      \"reference\": {\n        \"resource\": \"customers\",\n        \"fields\": \"id\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"frictionlessdata/#complete-example-multi-resource-data-package","title":"Complete Example: Multi-Resource Data Package","text":"<p>Here's a complete example showing how all the specifications work together:</p> <p>datapackage.json:</p> <pre><code>{\n  \"name\": \"ecommerce-sample-data\",\n  \"title\": \"E-commerce Sample Dataset\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Sample e-commerce data including customers, orders, and products\",\n  \"licenses\": [\n    {\n      \"name\": \"CC-BY-4.0\",\n      \"title\": \"Creative Commons Attribution 4.0\"\n    }\n  ],\n  \"resources\": [\n    {\n      \"name\": \"customers\",\n      \"path\": \"data/customers.csv\",\n      \"format\": \"csv\",\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"id\",\n            \"type\": \"integer\",\n            \"constraints\": {\"required\": true, \"unique\": true}\n          },\n          {\n            \"name\": \"name\",\n            \"type\": \"string\",\n            \"constraints\": {\"required\": true}\n          },\n          {\n            \"name\": \"email\",\n            \"type\": \"string\",\n            \"format\": \"email\",\n            \"constraints\": {\"required\": true, \"unique\": true}\n          },\n          {\n            \"name\": \"created_at\",\n            \"type\": \"datetime\"\n          }\n        ],\n        \"primaryKey\": \"id\"\n      }\n    },\n    {\n      \"name\": \"orders\",\n      \"path\": \"data/orders.csv\",\n      \"format\": \"csv\",\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"order_id\",\n            \"type\": \"integer\",\n            \"constraints\": {\"required\": true, \"unique\": true}\n          },\n          {\n            \"name\": \"customer_id\",\n            \"type\": \"integer\",\n            \"constraints\": {\"required\": true}\n          },\n          {\n            \"name\": \"order_date\",\n            \"type\": \"date\"\n          },\n          {\n            \"name\": \"total\",\n            \"type\": \"number\",\n            \"constraints\": {\"minimum\": 0}\n          }\n        ],\n        \"primaryKey\": \"order_id\",\n        \"foreignKeys\": [\n          {\n            \"fields\": \"customer_id\",\n            \"reference\": {\n              \"resource\": \"customers\",\n              \"fields\": \"id\"\n            }\n          }\n        ]\n      }\n    },\n    {\n      \"name\": \"product_categories\",\n      \"title\": \"Product Categories Lookup\",\n      \"data\": [\n        {\"id\": 1, \"name\": \"Electronics\"},\n        {\"id\": 2, \"name\": \"Clothing\"},\n        {\"id\": 3, \"name\": \"Books\"}\n      ],\n      \"schema\": {\n        \"fields\": [\n          {\"name\": \"id\", \"type\": \"integer\"},\n          {\"name\": \"name\", \"type\": \"string\"}\n        ],\n        \"primaryKey\": \"id\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"frictionlessdata/#benefits-and-use-cases","title":"Benefits and Use Cases","text":""},{"location":"frictionlessdata/#benefits","title":"Benefits","text":"<ol> <li>Self-describing data: Metadata travels with the data</li> <li>Validation: Schemas enable automatic data validation</li> <li>Interoperability: Standard format works across tools and platforms</li> <li>Documentation: Built-in documentation through descriptions</li> <li>Versioning: Track changes with version numbers</li> <li>Reproducibility: Clear provenance and structure</li> </ol>"},{"location":"frictionlessdata/#use-cases","title":"Use Cases","text":"<ul> <li>Research Data Management: Package research datasets with complete metadata</li> <li>Open Data Publishing: Share government or public data with clear schemas</li> <li>Data Pipelines: Standardize data flowing through ETL processes</li> <li>API Documentation: Describe API response structures</li> <li>Data Catalogs: Build searchable data repositories</li> <li>Data Quality: Validate data against defined schemas</li> </ul>"},{"location":"frictionlessdata/#tools-and-ecosystem","title":"Tools and Ecosystem","text":"<p>The Frictionless Data ecosystem includes:</p> <ul> <li>Frictionless Framework (Python): Create, validate, and transform data packages</li> <li>Data Package Creator: Web-based tool for creating data packages</li> <li>Goodtables: Data validation tool</li> <li>Libraries: Available in Python, JavaScript, R, and other languages</li> </ul>"},{"location":"frictionlessdata/#references","title":"References","text":"<ul> <li>Official Website: https://frictionlessdata.io/</li> <li>Specifications: https://specs.frictionlessdata.io/</li> <li>GitHub: https://github.com/frictionlessdata</li> </ul>"}]}